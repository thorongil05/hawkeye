{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"feature_extraction.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"pw7rlBguk9A5"},"source":["# Initialization\r\n","As first step we mount the Google Drive directory. Then, in order to speed up the overall computation, we copy and unzip the **food** and the **distractor** datasets directly into Colab. Due to the different skeletons of the datasets, for the Distractor dataset we also added a command to create the directory \"distractor\" to extract inside the unzipped dataset.\r\n","\r\n"," "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MJW_DdyfmPmT","executionInfo":{"status":"ok","timestamp":1609749152540,"user_tz":-60,"elapsed":19924,"user":{"displayName":"LORENZO BARIGLIANO","photoUrl":"","userId":"13429493376342490386"}},"outputId":"e68c08a3-0421-4918-e3b6-f4b116bd6f0d"},"source":["from google.colab import drive\r\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eidDs5JHmsnJ","executionInfo":{"status":"ok","timestamp":1609749529740,"user_tz":-60,"elapsed":371588,"user":{"displayName":"LORENZO BARIGLIANO","photoUrl":"","userId":"13429493376342490386"}}},"source":["!cp '/content/gdrive/MyDrive/[MIRCV]FoodWebSearch/food.zip' .\r\n","!unzip -q food.zip\r\n","!rm food.zip"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"GuDw61vFnjg0","executionInfo":{"status":"ok","timestamp":1609749765548,"user_tz":-60,"elapsed":215333,"user":{"displayName":"LORENZO BARIGLIANO","photoUrl":"","userId":"13429493376342490386"}}},"source":["!mkdir '/content/distractor'\r\n","!cp '/content/gdrive/MyDrive/[MIRCV]FoodWebSearch/mirflickr25k.zip' .\r\n","!unzip -q mirflickr25k.zip -d '/content/distractor'\r\n","!rm mirflickr25k.zip\r\n"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kgyi26mtp-Zt"},"source":["We create the variables for each dataset and for the batch size, assigning respective values."]},{"cell_type":"code","metadata":{"id":"wZ8RI96QoHme","executionInfo":{"status":"ok","timestamp":1609749801952,"user_tz":-60,"elapsed":8422,"user":{"displayName":"LORENZO BARIGLIANO","photoUrl":"","userId":"13429493376342490386"}}},"source":["import tensorflow as tf\r\n","import numpy as np\r\n","from os import listdir\r\n","\r\n","FOOD_DIR = '/content/food-101/images/'\r\n","DISTRACTOR_DIR = '/content/distractor/'\r\n","\r\n","BATCH_SIZE = 128 #to check"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vvrEuEc2qACM"},"source":["To speed up the application we choose to use the GPU provided by the machine. This command allows us to exploit the GPU."]},{"cell_type":"code","metadata":{"id":"Ea0rJHHNnz88","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609749811090,"user_tz":-60,"elapsed":6339,"user":{"displayName":"LORENZO BARIGLIANO","photoUrl":"","userId":"13429493376342490386"}},"outputId":"939f0a6a-6ab7-4b86-84ba-11bd66a57955"},"source":["# check hardware acceleration\r\n","device_name = tf.test.gpu_device_name()\r\n","print('Found GPU: ' , device_name)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Found GPU:  /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bysqS9k3qlxz"},"source":["# Datasets\r\n","\r\n","For each dataset we collect all the files. We use as **shuffle** parameters \"False\" in order to mantain the same order of the files respect to the original directory, for both datasets. As expected, the food dataset has 101000 files, divided in 101 lables, the distractor has 25000 files for a single class."]},{"cell_type":"code","metadata":{"id":"Yzjg19MloW3z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609749821507,"user_tz":-60,"elapsed":2592,"user":{"displayName":"LORENZO BARIGLIANO","photoUrl":"","userId":"13429493376342490386"}},"outputId":"4f06f621-30b5-4cec-855f-33fa26a3b7aa"},"source":["food_dataset = tf.keras.preprocessing.image_dataset_from_directory(\r\n","    FOOD_DIR,\r\n","    seed=123,\r\n","    shuffle=False,\r\n","    color_mode='rgb', \r\n","    image_size=(224, 224),\r\n","    batch_size=BATCH_SIZE)\r\n","\r\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Found 101000 files belonging to 101 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LEPUBHZcQiPl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609749848737,"user_tz":-60,"elapsed":1448,"user":{"displayName":"LORENZO BARIGLIANO","photoUrl":"","userId":"13429493376342490386"}},"outputId":"2a8d9e70-56d5-40f5-c70a-9d038704e4ab"},"source":["distractor_dataset = tf.keras.preprocessing.image_dataset_from_directory(\r\n","    DISTRACTOR_DIR,\r\n","    seed=123,\r\n","    shuffle=False, \r\n","    color_mode='rgb', \r\n","    image_size=(224, 224),\r\n","    batch_size=BATCH_SIZE)\r\n","\r\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Found 25000 files belonging to 1 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"L88m76iAsnWC"},"source":["# Preparing the structures\r\n","As first step of this section we need to generate a structure that contains all the ids of the images. As unique identifier we choose to use the original name of each file contained in the datasets. \r\n","\r\n","For the food dataset we need to iterate over all the directories and append all the names of the images in the structure **descriptors**.\r\n","\r\n","For the distractor dataset we have only a single directory to iterate over, so we retrieve the names in the **dataset_strings** structure and then we concatenate the two lists.\r\n","\r\n","The structure **descriptors** at the end contains the ids of the food dataset and the distractor ones, in this specific order."]},{"cell_type":"code","metadata":{"id":"7y3lB_Xa9IbG","executionInfo":{"status":"ok","timestamp":1609749870541,"user_tz":-60,"elapsed":13400,"user":{"displayName":"LORENZO BARIGLIANO","photoUrl":"","userId":"13429493376342490386"}}},"source":["list_food = []\r\n","dataset_strings = []\r\n","descriptors = []\r\n","for dir in listdir('/content/food-101/images/'):\r\n","  if dir != '.DS_Store':\r\n","    list_food.append(tf.data.Dataset.list_files('/content/food-101/images/' + dir + '/*.jpg', shuffle=False))\r\n","for i in list_food:\r\n","  dataset_strings.append([f.numpy() for f in i.take(-1)])\r\n","for i in dataset_strings:\r\n","  for j in i:\r\n","    elem = str(j).split('/')[-1].replace(\"'\",\"\")\r\n","    descriptors.append(elem)\r\n","\r\n","#generation of the ids\r\n","list_distractor = tf.data.Dataset.list_files(('/content/distractor/mirflickr/*.jpg'), shuffle=False)\r\n","dataset_strings = [str(f.numpy()).split('/')[-1].replace(\"'\",\"\") for f in list_distractor.take(-1)]\r\n","descriptors += dataset_strings\r\n","\r\n"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VSpbVNdTxKP4"},"source":["# Extracting features\r\n","We use a map function to apply the pre-processing step to all the images in both datasets.\r\n","Then we call the \"mobilenetv2.predict()\" function on the datasets, to extract the features, saving them in **food_features** and **distractor_features** respectively. We put these together in the **features_list** structure."]},{"cell_type":"code","metadata":{"id":"fNBA-rWir1cu","executionInfo":{"status":"ok","timestamp":1609749876498,"user_tz":-60,"elapsed":577,"user":{"displayName":"LORENZO BARIGLIANO","photoUrl":"","userId":"13429493376342490386"}}},"source":["#Pre-Processing\r\n","\r\n","def preprocess(images, labels):\r\n","  images = tf.keras.applications.mobilenet_v2.preprocess_input(images)\r\n","  return images, labels\r\n","  \r\n","food_dataset = food_dataset.map(preprocess, deterministic=True)\r\n","distractor_dataset = distractor_dataset.map(preprocess, deterministic=True)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZgTk9QQ9Y95o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609750394119,"user_tz":-60,"elapsed":513542,"user":{"displayName":"LORENZO BARIGLIANO","photoUrl":"","userId":"13429493376342490386"}},"outputId":"b516715e-16f6-417f-c2cf-c90a6a8efc8e"},"source":["#extracting features\r\n","\r\n","mobilenetv2 = tf.keras.applications.MobileNetV2(\r\n","    weights='imagenet',\r\n","    include_top=False,\r\n","    pooling = 'max', \r\n","    input_shape=(224,224,3)\r\n",")\r\n","\r\n","\r\n","food_features = mobilenetv2.predict(food_dataset, batch_size=BATCH_SIZE, verbose=1)\r\n","distractor_features = mobilenetv2.predict(distractor_dataset, batch_size=BATCH_SIZE, verbose=1)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","9412608/9406464 [==============================] - 0s 0us/step\n","790/790 [==============================] - 398s 495ms/step\n","196/196 [==============================] - 113s 575ms/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZPbUrvrneEH4","executionInfo":{"status":"ok","timestamp":1609750401283,"user_tz":-60,"elapsed":554,"user":{"displayName":"LORENZO BARIGLIANO","photoUrl":"","userId":"13429493376342490386"}}},"source":["#generating features_list\r\n","features_list = list(food_features) + list(distractor_features)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UqCMARo6yaEW"},"source":["# Saving as two numpy files\r\n","As final step we generate two **.npy** files, one for the ids and one for the features."]},{"cell_type":"code","metadata":{"id":"kStUyBWIfKRf","executionInfo":{"status":"ok","timestamp":1609750453650,"user_tz":-60,"elapsed":3983,"user":{"displayName":"LORENZO BARIGLIANO","photoUrl":"","userId":"13429493376342490386"}}},"source":["#save as 2 numpy files\r\n","np.save('/content/gdrive/MyDrive/[MIRCV]FoodWebSearch/deployment/mn_id.npy', descriptors)\r\n","np.save('/content/gdrive/MyDrive/[MIRCV]FoodWebSearch/deployment/mn_features.npy', features_list)\r\n"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IA0a1FqFy96m"},"source":["# Fine-tuned features extraction\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"mfPZch8Fh9om"},"source":["As last step we extract the features from our fine-tuned model."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g36cLPffWzX5","executionInfo":{"status":"ok","timestamp":1609750910423,"user_tz":-60,"elapsed":452062,"user":{"displayName":"LORENZO BARIGLIANO","photoUrl":"","userId":"13429493376342490386"}},"outputId":"6a0bd2e9-a46a-41b0-fec7-9594c33becea"},"source":["model = tf.keras.models.load_model('/content/gdrive/MyDrive/[MIRCV]FoodWebSearch/deployment/food_classifier.h5')\r\n","\r\n","model = tf.keras.Model(inputs=model.input, outputs=model.get_layer('dense_hidden').output) #remove classifier from model\r\n","\r\n","food_features_finetuned = model.predict(food_dataset, batch_size=BATCH_SIZE, verbose=1)\r\n","distractor_features_finetuned = model.predict(distractor_dataset, batch_size=BATCH_SIZE, verbose=1)\r\n","\r\n","#generating features_list\r\n","features_list_finetuned = list(food_features_finetuned) + list(distractor_features_finetuned)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["790/790 [==============================] - 338s 426ms/step\n","196/196 [==============================] - 111s 565ms/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rH0jzyXFYpxb","executionInfo":{"status":"ok","timestamp":1609750937616,"user_tz":-60,"elapsed":1511,"user":{"displayName":"LORENZO BARIGLIANO","photoUrl":"","userId":"13429493376342490386"}}},"source":["#save as 2 numpy files\r\n","np.save('/content/gdrive/MyDrive/[MIRCV]FoodWebSearch/deployment/ft_id.npy', descriptors)\r\n","np.save('/content/gdrive/MyDrive/[MIRCV]FoodWebSearch/deployment/ft_features.npy', features_list_finetuned)"],"execution_count":16,"outputs":[]}]}