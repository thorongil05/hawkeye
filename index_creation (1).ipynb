{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "index_creation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qA_mRGwuUMiP",
        "odU0xysW3kUr",
        "mIxp7mY7sECX",
        "Jar0skz-sPsx"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6H2rcrVSh3E",
        "outputId": "44b419d0-2eda-471f-85bd-4139ae5f6888"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA_mRGwuUMiP"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr1ZrF1AUR8f"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from scipy.spatial import distance as d\n",
        "import os\n",
        "import math\n",
        "import pandas as pd\n",
        "import time\n",
        "import json\n",
        "\n",
        "TEST_DIR = '/content/gdrive/My Drive/test-folder/'\n",
        "\n",
        "LEAF_FOLDER = '/content/gdrive/My Drive/[MIRCV]FoodWebSearch/antonio-tests'\n",
        "\n",
        "TEST_FILE_1 = os.path.join(TEST_DIR, \"test-tree-construction-data.npy\")\n",
        "TEST_FILE_2 = os.path.join(TEST_DIR, \"test-tree-construction-data-2.npy\")\n",
        "TEST_FILE_3 = os.path.join(TEST_DIR, \"test-tree-construction-data-3.npy\")\n",
        "\n",
        "\n",
        "TEST_PATH = \"/content/gdrive/My Drive/[MIRCV]FoodWebSearch/antonio-tests\"\n",
        "\n",
        "FEATURES_PATH = \"/content/gdrive/My Drive/[MIRCV]FoodWebSearch/features.csv\"\n",
        "FEATURES_PATH_TEST_1 = \"/content/gdrive/My Drive/[MIRCV]FoodWebSearch/antonio-tests/features-test-1.npy\"\n",
        "FEATURES_NAMES_TEST_1 = \"/content/gdrive/My Drive/[MIRCV]FoodWebSearch/antonio-tests/features-names-test-1.npy\"\n",
        "\n",
        "FEATURES_PATH_TEST_2 = \"/content/gdrive/My Drive/[MIRCV]FoodWebSearch/antonio-tests/features-test-2.npy\"\n",
        "FEATURES_NAMES_TEST_2 = \"/content/gdrive/My Drive/[MIRCV]FoodWebSearch/antonio-tests/features-names-test-2.npy\"\n",
        "\n",
        "FEATURES_PATH_TEST_3 = \"/content/gdrive/My Drive/[MIRCV]FoodWebSearch/antonio-tests/features-test-3.npy\"\n",
        "FEATURES_NAMES_TEST_3 = \"/content/gdrive/My Drive/[MIRCV]FoodWebSearch/antonio-tests/features-names-test-3.npy\"\n",
        "\n",
        "\n",
        "ID_DEPLOYMENT = \"/content/gdrive/MyDrive/[MIRCV]FoodWebSearch/id.npy\"\n",
        "FEATURES_DEPLOYMENT = \"/content/gdrive/MyDrive/[MIRCV]FoodWebSearch/features.npy\"\n",
        "\n",
        "FINE_TUNED_ID = '/content/gdrive/MyDrive/[MIRCV]FoodWebSearch/deployment/ft_id.npy'\n",
        "FINE_TUNED_FEATURES = '/content/gdrive/MyDrive/[MIRCV]FoodWebSearch/deployment/ft_features.npy'\n",
        "\n",
        "MN_ID = '/content/gdrive/MyDrive/[MIRCV]FoodWebSearch/deployment/mn_id.npy'\n",
        "MN_FEATURES = '/content/gdrive/MyDrive/[MIRCV]FoodWebSearch/deployment/mn_features.npy'\n",
        "\n",
        "INDEX_DIR = \"/content/gdrive/MyDrive/[MIRCV]FoodWebSearch/deployment\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQxpe2EiByvI"
      },
      "source": [
        "Create the datasets for tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew_T12SL94UM"
      },
      "source": [
        "np.save(FEATURES_PATH_TEST_2, [[63, 27, 38], [60.21, 24, 26], [60, 82, 0], [19, 39, 52], [10, 57, 98], \n",
        "                      [46, 19, 41], [32, 13, 6], [14, 74, 12], [98, 27, 22], [59, 62, 0], \n",
        "                      [4, 9, 22], [62, 56, 63], [38, 86, 60], [66, 13, 90], [95, 56, 70], \n",
        "                      [11, 71, 14], [56, 97, 40], [94, 6, 52], [63, 67, 91], [88, 70, 15], \n",
        "                      [72, 98, 32], [66, 61, 89], [92, 86, 13], [40, 97, 35], [26, 3, 10], \n",
        "                      [40, 61, 99], [49, 83, 24], [54, 32, 22], [70, 42, 55], [43, 34, 61]])\n",
        "np.save(FEATURES_NAMES_TEST_2, [\"img_\" + str(i) for i in range(30)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8FqM4ns-hCE"
      },
      "source": [
        "np.save(FEATURES_NAMES_TEST_3, [[56, 0, 26, 95], [73, 40, 13, 47], [46, 81, 16, 78], [82, 9, 83, 32], [65, 59, 85, 30], \n",
        "                      [88, 49, 11, 19], [65, 76, 27, 58], [17, 84, 91, 33], [93, 80, 67, 64], [58, 91, 75, 38], \n",
        "                      [46, 69, 2, 49], [26, 39, 35, 70], [35, 95, 88, 90], [51, 84, 68, 72], [93, 75, 24, 88], \n",
        "                      [77, 82, 87, 12], [13, 16, 93, 12], [35, 18, 61, 42], [58, 18, 29, 23], [51, 24, 26, 99], \n",
        "                      [20, 28, 34, 12], [40, 21, 62, 14], [78, 79, 18, 23], [99, 22, 48, 79], [20, 73, 6, 64], \n",
        "                      [41, 14, 35, 67], [20, 4, 73, 74], [50, 84, 90, 12], [86, 64, 36, 58], [11, 51, 70, 32], \n",
        "                      [62, 91, 39, 84], [82, 28, 35, 29], [38, 22, 40, 67], [45, 51, 30, 44], [98, 2, 0, 49], \n",
        "                      [72, 57, 87, 80], [42, 32, 19, 93], [51, 50, 73, 6], [63, 40, 50, 75], [10, 84, 56, 27], \n",
        "                      [14, 34, 30, 85], [55, 44, 96, 93], [37, 73, 83, 42], [51, 4, 25, 8], [42, 10, 19, 82], \n",
        "                      [11, 29, 18, 31], [19, 28, 47, 39], [4, 69, 25, 28], [78, 12, 30, 48], [87, 28, 10, 24], \n",
        "                      [25, 93, 39, 97], [4, 62, 39, 89], [61, 29, 38, 82], [53, 49, 72, 46], [22, 86, 7, 50], \n",
        "                      [14, 92, 74, 65], [91, 67, 45, 21], [69, 12, 60, 52], [80, 3, 89, 93], [26, 70, 8, 72], \n",
        "                      [44, 36, 38, 92], [99, 25, 15, 49], [48, 79, 78, 38], [35, 67, 33, 53], [80, 68, 43, 41], \n",
        "                      [28, 19, 69, 37], [53, 58, 0, 17], [69, 7, 62, 73], [43, 34, 30, 29], [43, 41, 27, 57], \n",
        "                      [17, 59, 84, 91], [65, 55, 7, 82], [48, 3, 49, 99], [63, 44, 62, 9], [48, 53, 26, 39], \n",
        "                      [2, 17, 25, 31], [64, 30, 95, 15], [82, 76, 88, 15], [53, 31, 68, 76], [7, 36, 70, 71], \n",
        "                      [10, 31, 30, 25], [8, 43, 98, 25], [46, 97, 90, 19], [38, 2, 36, 51], [56, 24, 31, 97], \n",
        "                      [77, 45, 2, 69], [80, 52, 44, 10], [75, 84, 22, 51], [40, 49, 24, 65], [46, 32, 44, 66], \n",
        "                      [33, 13, 16, 34], [50, 20, 29, 52], [85, 54, 43, 78], [12, 19, 14, 64], [22, 74, 13, 94], \n",
        "                      [14, 26, 10, 15], [81, 25, 41, 86], [74, 23, 79, 54], [49, 2, 60, 7], [68, 26, 88, 75]])\n",
        "np.save(FEATURES_NAMES_TEST_3, [\"img_\" + str(i) for i in range(100)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--Pgf1ZoQfCf"
      },
      "source": [
        "# Create Tree Data Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odU0xysW3kUr"
      },
      "source": [
        "##The Node\n",
        "The class Node represents a node in the tree. \n",
        "We can have two types of nodes:\n",
        "- internal node\n",
        "- leaf node\n",
        "\n",
        "All the nodes have an id, in order to store the tree on disk, preserving its structure.\n",
        "\n",
        "####Internal Node\n",
        "In the case of an internal node, the class has the following parameters:\n",
        "- reference to the right child\n",
        "- reference to the left child\n",
        "- the value of the node, it's the pivot in this application: a numpy array that represent a point in the space\n",
        "- the median: the value of the median is computed on the sorted distances between the pivot and the other values of the set\n",
        "\n",
        "####Leaf Node\n",
        "\n",
        "In the case of a leaf node, the class has the following fields:\n",
        "- the pivot\n",
        "- the median\n",
        "- reference to the file in which are stored the objects on the left\n",
        "- reference to the file in which are stored the objects on the right"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h9Hb7EB3MoC"
      },
      "source": [
        "class NumpyEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        if isinstance(obj, None):\n",
        "            return \"\"\n",
        "        return json.JSONEncoder.default(self, obj)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIhDImrBQnjj"
      },
      "source": [
        "class Node:\n",
        "\n",
        "  def __init__(self, id, is_leaf, **kwargs):\n",
        "    self.parent = kwargs.get(\"parent\", None)\n",
        "    self.id = id\n",
        "    self.is_leaf = is_leaf\n",
        "    self.pivot = kwargs.get(\"pivot\", None)\n",
        "    self.median = kwargs.get(\"median\", -1)\n",
        "    if self.is_leaf:\n",
        "      self.objects = kwargs.get(\"objects\", [])\n",
        "      self.file_path_s_1, self.file_path_s_2 = \"\", \"\"\n",
        "    else:\n",
        "      self.right = kwargs.get(\"right\", None)\n",
        "      self.left = kwargs.get(\"left\", None)\n",
        "\n",
        "  def set_parameters(self, pivot, median):\n",
        "    self.pivot = pivot\n",
        "    self.median = median\n",
        "\n",
        "  def add_children(self, left, right):\n",
        "    self.left = left\n",
        "    self.right = right\n",
        "\n",
        "  def add_objects(self, s_1, s_2):\n",
        "    self.objects_left = s_1\n",
        "    self.objects_right = s_2\n",
        "\n",
        "  def save_leaf_objects_on_disk(self, file_path, s_1, s_2):\n",
        "    self.file_path_s_1 = file_path + \"_subset_1.npy\"\n",
        "    self.file_path_s_2 = file_path + \"_subset_2.npy\"\n",
        "    np.save(self.file_path_s_1, np.array(s_1, dtype=object))\n",
        "    np.save(self.file_path_s_2, np.array(s_2, dtype=object))\n",
        "\n",
        "  def load_objects_from_disk(self, left=True, right=True):\n",
        "    if left and not right:\n",
        "      result = np.load(self.file_path_s_1, allow_pickle=True)\n",
        "      return result\n",
        "    if right and not left:\n",
        "      result = np.load(self.file_path_s_1, allow_pickle=True)\n",
        "      return result\n",
        "    s_1 = np.load(self.file_path_s_1, allow_pickle=True)\n",
        "    s_2 = np.load(self.file_path_s_2, allow_pickle=True)\n",
        "    result = np.concatenate((s_1, s_2))\n",
        "    return result\n",
        "\n",
        "  def get_node_name(self):\n",
        "    return self.id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFLASx_e6gk5"
      },
      "source": [
        "##The Vantage Point Tree\n",
        "The Vantage Point Tree is modeled as a class, that provides us the methods to:\n",
        "- create the tree from a dataset\n",
        "- search the k-nearest neighbors objects, given a query\n",
        "- print the tree<br>\n",
        "\n",
        "All these methods are based on recursion.<br>\n",
        "The Vantage Point Tree can be created in two modes:\n",
        "1. Test mode: in order to test the tree on very small datasets\n",
        "2. Disk mode: in this mode we can handle very huge datasets, by storing the objects on disk and keeping in the tree just the reference to the files\n",
        "\n",
        "### Save Tree on disk\n",
        "\n",
        "The save method use the recursion. For each node, a json element is created, each element contains:\n",
        "- node id\n",
        "- boolean to recognize a leaf\n",
        "- the pivot as numpy array\n",
        "\n",
        "If we deal with an internal node, we have:\n",
        "- left child id\n",
        "- right child id\n",
        "\n",
        "On the other hand, the leaf node has:\n",
        "- path of the file containing the objects on the left\n",
        "- path of the file containing the objects on the right\n",
        "\n",
        "At the end we will have a json array, each entry represents a node.\n",
        "This json is saved on disk.\n",
        "\n",
        "### Load Tree from disk\n",
        "\n",
        "The load method works in the opposite way with respect to save. \n",
        "It also uses recursion:\n",
        "1. the algorithm loads and deserializes the json\n",
        "2. it finds the node in the json array using the id (node has id \"0\")\n",
        "3. it builds a node object from the json\n",
        "4. it finds the left child through the left child id in the entry\n",
        "5. it finds the right child through the right child id in the entry\n",
        "6. it builds the nodes recursively until it reaches the leaves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnXmnTbIUgsC"
      },
      "source": [
        "class VP_Tree:\n",
        "\n",
        "  def __init__(self, index_name, height, disk_mode=True, leaves_path=None):\n",
        "    self.root = None\n",
        "    self.index_name = index_name\n",
        "    self.height = height #to review\n",
        "    self.disk_mode = disk_mode\n",
        "    self.leaves_path = leaves_path\n",
        "\n",
        "  def create_vptree(self, names_path, features_path):\n",
        "    start = time.time()\n",
        "    data = VP_Tree.read_data(names_path, features_path)\n",
        "    n = len(data)\n",
        "    print(\"Number of data:\", n)\n",
        "    max_height = math.floor(math.log(n,2)-1)\n",
        "    print(\"The max height of the tree is:\", max_height)\n",
        "    if self.height > max_height: self.height = max_height \n",
        "    #take 1 pivot randomly and set pivot as root\n",
        "    self.root, s_1, s_2 = self.partition_by_median(data)\n",
        "    print(\"Tree is building\")\n",
        "    self.create_tree_level(self.root, s_1, s_2, 1)\n",
        "    end = time.time()\n",
        "    print(\"Building of the tree completed in:\", end-start, \"s\")\n",
        "  \n",
        "  def create_tree_level(self, node, s_1, s_2, iteration):\n",
        "      is_leaf = iteration + 1 >= self.height\n",
        "      left_node, s_1_left, s_2_left = self.partition_by_median(s_1, parent=node,is_left=True, is_leaf=is_leaf)\n",
        "      right_node, s_1_right, s_2_right = self.partition_by_median(s_2, parent=node,is_left=False, is_leaf=is_leaf)\n",
        "      node.add_children(right_node, left_node)\n",
        "      if iteration + 1 < self.height:\n",
        "        self.create_tree_level(left_node, s_1_left, s_2_left, iteration + 1)\n",
        "        self.create_tree_level(right_node, s_1_right, s_2_right, iteration + 1)\n",
        "      else:\n",
        "        if self.disk_mode:\n",
        "          left_path = self.get_leaves_path(left_node.get_node_name())\n",
        "          right_path = self.get_leaves_path(right_node.get_node_name())\n",
        "          left_node.save_leaf_objects_on_disk(left_path, s_1_left, s_2_left)\n",
        "          right_node.save_leaf_objects_on_disk(right_path, s_1_right, s_2_right)\n",
        "        else:\n",
        "          left_node.add_objects(s_1_left, s_2_left)\n",
        "          right_node.add_objects(s_1_right, s_2_right)\n",
        "\n",
        "  def partition_by_median(self, data, parent=None,is_left=False,is_leaf=False):\n",
        "    pivot_index = random.choice(range(len(data)))\n",
        "    pivot = data[pivot_index]\n",
        "    del data[pivot_index]\n",
        "    #compute all the distances\n",
        "    distances = np.array([d.euclidean(pivot[1],element[1]) for element in data])\n",
        "    #sort the distances\n",
        "    zipped_data_distances = sorted(zip(data, distances), key= lambda x:x[1])\n",
        "    ordered_data, distances = zip(*zipped_data_distances)\n",
        "    median = np.median(distances)\n",
        "    #get the median\n",
        "    s_1 = [element for element, distance in zipped_data_distances if distance <= median]\n",
        "    s_2 = [element for element, distance in zipped_data_distances if distance >= median]\n",
        "    #update node\n",
        "    if parent == None:\n",
        "      node = Node(id=\"0\", is_leaf=is_leaf, pivot=pivot, median=median)\n",
        "    else:\n",
        "      node_id = parent.id + str(0 if is_left else 1)\n",
        "      node = Node(node_id, is_leaf=is_leaf, pivot=pivot, median=median)\n",
        "    return node, s_1, s_2\n",
        "\n",
        "  def save_vptree(file_path, tree):\n",
        "    if not os.path.exists(file_path): os.mkdir(file_path)\n",
        "    file = os.path.join(file_path, tree.index_name + '.json')\n",
        "    if os.path.exists(file):\n",
        "      os.remove(file)\n",
        "    with open(file, 'a') as json_file:\n",
        "      index_json = {\"index\": tree.index_name, \"nodes\":[], \"height\":tree.height}\n",
        "      VP_Tree.save_node(tree.root, index_json)\n",
        "      vp_tree_json = json.dumps(index_json, cls=NumpyEncoder)\n",
        "      json_file.write(vp_tree_json)\n",
        "      print(\"File saved correctly in:\", file)\n",
        "    return file\n",
        "  \n",
        "  def save_node(node, index_json):\n",
        "    if node.is_leaf:\n",
        "        row_json={\"is_leaf\":True, \n",
        "                    \"id\":node.id,\n",
        "                    \"pivot\" : node.pivot,\n",
        "                    \"median\":node.median, \n",
        "                    \"left_file\":node.file_path_s_1, \n",
        "                    \"right_file\":node.file_path_s_2}\n",
        "        index_json[\"nodes\"].append(row_json)\n",
        "    else:\n",
        "        row_json={\"is_leaf\":False,\n",
        "                  \"id\":node.id, \n",
        "                  \"pivot\": node.pivot,\n",
        "                  \"median\": node.median,\n",
        "                  \"right_child\":node.right.id,\n",
        "                  \"left_child\":node.left.id}\n",
        "        index_json[\"nodes\"].append(row_json)\n",
        "        VP_Tree.save_node(node.left, index_json)\n",
        "        VP_Tree.save_node(node.right,index_json)\n",
        "    return\n",
        "\n",
        "  def load_vptree(path):\n",
        "    if not os.path.exists:\n",
        "      print(\"the path do not exist\")\n",
        "      return None\n",
        "    entry_list=[]\n",
        "    with open(path,'r', encoding='utf-8') as f:\n",
        "      json_tree = json.load(f)\n",
        "      entry_list=json_tree[\"nodes\"]\n",
        "    root_node=VP_Tree.parse_node('0',entry_list)\n",
        "    index_name = json_tree[\"index\"]\n",
        "    height = json_tree[\"height\"]\n",
        "    vp_tree = VP_Tree(index_name=index_name,height=height,leaves_path=path)\n",
        "    vp_tree.root = root_node\n",
        "    print(\"Tree loaded correctly\")\n",
        "    return vp_tree\n",
        "\n",
        "  def parse_node(id, nodes):\n",
        "    node_json = None\n",
        "    for element in nodes:\n",
        "      if element[\"id\"]==id:\n",
        "        node_json = element\n",
        "    node=Node(id=node_json[\"id\"], is_leaf=node_json[\"is_leaf\"], \n",
        "              pivot=node_json[\"pivot\"], median=node_json[\"median\"])\n",
        "    if (node.is_leaf):\n",
        "      node.file_path_s_1=node_json[\"left_file\"]\n",
        "      node.file_path_s_2=node_json[\"right_file\"]\n",
        "    else:\n",
        "      right=VP_Tree.parse_node(node_json[\"right_child\"],nodes)\n",
        "      left=VP_Tree.parse_node(node_json[\"left_child\"],nodes)\n",
        "      node.add_children(left, right)\n",
        "    return node\n",
        "\n",
        "  def knn_search(self, k, query):\n",
        "    start = time.time()\n",
        "    nn = [None for i in range(k)]\n",
        "    d_nn = [math.inf for i in range(k)]\n",
        "    nn, d_nn = self.search_subtree(self.root, nn, d_nn, k, query)\n",
        "    end = time.time()\n",
        "    print(\"Query answered in\", end-start, \" s\")\n",
        "    return self.reorder_list_on_distances(nn, d_nn, desc=False)\n",
        "\n",
        "  def search_subtree(self, node, nn, d_nn, k, query):\n",
        "    #print(nn)\n",
        "    pivot, median = node.pivot, node.median\n",
        "    distance = d.euclidean(pivot[1], query)\n",
        "    if distance <= d_nn[0]:\n",
        "      d_nn[0] = distance\n",
        "      nn[0] = pivot\n",
        "      nn, d_nn = self.reorder_list_on_distances(nn, d_nn)\n",
        "    if node.is_leaf:\n",
        "      return self.search_in_leaf(node, nn, d_nn, k, query)\n",
        "    if distance - d_nn[0] <= median:\n",
        "      nn, d_nn = self.search_subtree(node.left, nn, d_nn, k, query)\n",
        "    if distance + d_nn[0] >= median:\n",
        "      nn, d_nn = self.search_subtree(node.right, nn, d_nn, k, query)\n",
        "    return nn, d_nn\n",
        "\n",
        "  def search_in_leaf(self, node, nn, d_nn, k, query):\n",
        "    objects = []\n",
        "    distance_pivot = d.euclidean(node.pivot[1], query)\n",
        "    left, right = False, False\n",
        "    if self.disk_mode:\n",
        "      if distance_pivot - d_nn[0] <= node.median: left = True\n",
        "      if distance_pivot + d_nn[0] >= node.median: right = True\n",
        "      objects = node.load_objects_from_disk(left=left, right=right)\n",
        "    else:\n",
        "      objects = node.objects_left + node.objects_right\n",
        "    for obj in objects:\n",
        "      distance = d.euclidean(obj[1], query)\n",
        "      if distance < d_nn[0]:\n",
        "        nn[0] = obj\n",
        "        d_nn[0] = distance\n",
        "        nn, d_nn = self.reorder_list_on_distances(nn, d_nn)\n",
        "    return nn, d_nn\n",
        "\n",
        "  def reorder_list_on_distances(self, nn, d_nn, desc=True):\n",
        "      zipped = sorted(zip(nn, d_nn), key= lambda x:x[1], reverse=desc)\n",
        "      nn, d_nn = zip(*zipped)\n",
        "      return list(nn), list(d_nn)\n",
        "\n",
        "  def print_tree(node, level, disk_mode=True):\n",
        "    indentation = \"\\n\" + str(level * \"\\t\")\n",
        "    response = \"id: \" + node.id + \" \" + str(node.pivot)\n",
        "    if node.is_leaf:\n",
        "      if disk_mode: \n",
        "        response += indentation + str(node.file_path_s_1)\n",
        "        response += indentation + str(node.file_path_s_2)\n",
        "      else:\n",
        "        response += indentation + str(node.objects_left)\n",
        "        response += indentation + str(node.objects_right)\n",
        "      return response\n",
        "    response += indentation + VP_Tree.print_tree(node=node.right, level=level+1, disk_mode=disk_mode)\n",
        "    response += indentation + VP_Tree.print_tree(node=node.left, level=level+1, disk_mode=disk_mode)\n",
        "    return response\n",
        "\n",
        "  def get_leaves_path(self, file_name):\n",
        "    if not self.leaves_path is None:\n",
        "      directory = os.path.join(self.leaves_path, self.index_name)\n",
        "    else: directory = os.path.join(LEAF_FOLDER, self.index_name)\n",
        "    if not os.path.exists(directory):\n",
        "      os.mkdir(directory)\n",
        "    leaves_directory = os.path.join(directory, \"leaves_\"+ str(self.height))\n",
        "    if not os.path.exists(leaves_directory):\n",
        "      os.mkdir(leaves_directory)\n",
        "    return os.path.join(leaves_directory, file_name)\n",
        "\n",
        "  def read_data(file_path_names, file_path_features):\n",
        "    names = np.load(file_path_names)\n",
        "    features = np.load(file_path_features)\n",
        "    return [(name, feature) for name, feature in zip(names, features)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uqx0bmMrNGl"
      },
      "source": [
        "#Deployment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIxp7mY7sECX"
      },
      "source": [
        "## Index MN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og1n-0H5rSrM"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  vantage_point_tree = VP_Tree(\"index-mn\",height=10, disk_mode=True, leaves_path=INDEX_DIR)\n",
        "  vantage_point_tree.create_vptree(MN_ID, MN_FEATURES)\n",
        "\n",
        "  index_name = vantage_point_tree.index_name\n",
        "  dest_folder = os.path.join(INDEX_DIR, index_name)\n",
        "  print(\"Destination Folder: \", dest_folder)\n",
        "\n",
        "  VP_Tree.save_vptree(dest_folder,vantage_point_tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C0709azIRNJ",
        "outputId": "c250be2f-14cf-43ba-874f-22d243c74422"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  dir = os.path.join(INDEX_DIR,vantage_point_tree.index_name)\n",
        "  dir = os.path.join(dir, \"leaves\")\n",
        "  leaf = np.load(os.path.join(dir, \"1111111111_subset_1.npy\"), allow_pickle=True)\n",
        "  print(\"Objects per leaf:\", len(leaf))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vw6gopS-pEWA",
        "outputId": "e0d60370-f741-4314-cabd-2ccfdc727e41"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  dest_folder = os.path.join(INDEX_DIR, \"index/index.json\")\n",
        "  vantage_point_tree = VP_Tree.load_vptree(dest_folder)\n",
        "  query = [random.randint(-2,2) for _ in range(1280)]\n",
        "  start = time.time()\n",
        "  nn, d_nn = vantage_point_tree.knn_search(k=10, query=query)\n",
        "  end = time.time()\n",
        "  print(\"Results:\", [element[0] for element in nn])\n",
        "  print(\"Ricerca effettuata in:\", end - start, \"s\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tree loaded correctly\n",
            "Query [-1, -1, 1, 1, -1, -2, -2, -1, 0, -2, 0, 2, 0, 0, 1, -1, -2, 0, 0, 1, 2, -1, 1, -1, 0, 1, 2, -1, -2, 2, 0, -2, -2, -2, 2, 1, -1, -2, 1, -2, 0, 1, -1, 1, 2, 2, 0, 0, -2, 2, 2, 1, 1, 2, 2, -2, 0, -2, 1, -1, -2, 0, 1, -2, 1, -1, -2, -2, 1, 0, 0, 1, -2, -1, -1, -1, 1, -1, 2, 2, 1, -1, 2, 0, -2, 1, 2, -2, 2, -2, 0, 2, 0, -1, 2, -1, 2, 1, -1, 2, -1, 1, -2, 0, 2, 0, 0, 1, -1, 0, -2, 1, 1, 0, 2, 0, -1, 1, -2, 2, 1, -2, 2, -1, -1, 2, -2, 2, 2, -2, 0, 0, 1, -1, 2, 1, 0, -2, 2, -1, 0, 1, -2, 0, 0, 0, 1, -1, 1, 2, 1, 1, 1, -1, 1, -2, 0, 0, 2, -1, 1, 0, 2, -1, -2, -2, 1, -1, -2, 2, 2, -2, 2, 2, 1, 2, 2, 2, -1, 1, 0, 0, 0, 1, -1, -1, -1, 1, 0, 0, -1, 1, 0, -2, 0, -1, 2, -1, 1, 2, -2, -2, -1, -2, -1, 0, -1, -2, -2, -2, 0, 2, -1, 0, 2, 0, -2, -1, 2, 0, 1, -1, -2, -2, 0, 2, 2, -2, -1, -2, 1, 0, 1, -1, -1, -2, -2, 2, 1, 0, -1, 1, -1, -2, 2, -2, 1, -1, -1, 2, -1, 2, -1, -2, -2, 1, -1, 0, 0, 1, 1, 2, 0, 1, 2, -2, -2, 2, 1, -2, -1, 0, 2, 0, 2, 0, 2, 1, -1, -2, 2, 2, 1, 0, 1, -1, 1, 1, -2, -2, -2, 0, 2, 0, 1, -1, 2, 0, -2, 1, -2, -1, 0, 1, -1, 0, -1, -2, -2, 0, -1, 2, -1, 1, -1, 0, -2, 0, -1, 1, -1, -1, -2, -1, -2, 2, -2, 0, 0, 1, 2, 2, 2, 1, 2, -2, 0, 1, 0, 1, -1, 0, 1, -1, 0, 1, 2, 0, 1, 2, 0, -2, 1, 1, 1, 0, -1, -2, -2, -1, 2, 0, 0, -1, 2, -1, 1, 1, 0, 0, 0, -2, 0, 1, 0, 1, 1, 2, 0, 2, -2, 1, 0, 2, 1, 0, -1, 0, 1, -1, -2, -2, -2, 2, 0, 2, -1, -2, -2, 0, 0, 0, -2, 1, -2, 0, 0, -2, -1, 2, -1, -1, 1, -1, -1, 0, 2, 2, -1, 2, 1, 2, -2, 2, -1, -1, 2, 0, 0, 0, -1, -2, 0, 0, 0, 1, 0, 1, 0, 2, -1, 1, 0, 2, 1, 2, 2, -2, -2, 2, 2, -2, 1, -1, 1, 2, 2, 0, 1, -2, 2, -2, 1, 2, -1, 2, 2, 1, -1, -2, 1, -1, 2, 0, 2, 0, 1, -1, 2, 0, 0, -2, -1, -1, 1, -2, 0, 1, -2, -1, -2, 0, 1, 1, 1, -1, 2, -2, -1, 0, 0, -2, 0, 1, 0, -2, -1, 1, 1, -1, -1, 0, 2, -2, 0, 0, 0, -2, 2, 0, -1, 1, 2, -2, 1, 2, -2, 2, -2, 0, 1, 2, 0, 1, 2, -2, -1, -2, -1, 2, 0, 0, 2, 0, -1, 0, 1, 2, 1, 0, 1, 0, -2, 2, 0, -2, 0, 0, -2, 1, -1, -1, 0, -1, -2, -1, -2, 0, -2, 1, -2, 0, 2, -2, 0, -1, 2, 1, -1, 1, 2, -1, 2, -2, -2, 2, -2, 2, 0, -1, 0, -2, 2, 2, 2, 0, 0, -2, 0, 2, 2, 2, 1, -1, -2, 2, 2, 1, -2, 2, 0, 0, 0, 0, 1, -2, -2, 2, 0, -1, -1, 2, 2, -1, 1, -1, -2, -1, 1, -1, -2, -1, -1, 0, -1, 1, 2, 0, 1, -2, 1, 0, -2, -1, 1, 2, 2, -2, 2, 0, 0, 0, -2, -2, 0, -1, 2, -2, 1, 2, 0, 0, 0, -1, 0, 2, 0, -2, 1, 0, 0, -2, -2, -2, 1, -2, -2, 0, 2, -2, 2, 2, 2, -1, 1, -2, 2, 0, -1, 1, -2, 1, -2, 0, 0, 0, 1, 1, -1, -2, -2, -1, 0, -1, -1, 0, 0, 1, -2, 1, -1, -1, -1, 0, 2, 2, -2, -2, 0, -2, 2, 0, 2, 1, -2, 0, -1, -1, -1, 2, -1, -1, -2, -1, -1, 1, 0, 1, 1, -1, 0, 2, 0, -2, -1, -2, 0, -2, 0, -1, 1, 0, 0, -1, -2, 1, 2, 2, 0, -1, 0, 0, -2, -2, -2, 1, -2, 1, 1, -1, 0, 2, 2, 1, -1, -2, -1, -2, -1, -2, 0, 1, -1, 0, 1, 1, -1, -1, 2, -1, -1, 1, 0, 2, 0, 2, 0, 2, -1, 1, 1, 1, 0, -2, 0, -1, 2, -1, -1, 1, 0, 0, 0, 0, -1, -2, 1, 2, 0, -2, 1, -2, 2, -2, 1, 0, 2, 1, 2, 1, 2, 1, -1, -2, -2, 0, -1, -2, -2, -1, -2, 2, 1, -1, -2, 2, 2, 1, -1, 2, 1, 1, 1, -1, -2, -2, 2, -1, -1, 2, -2, 2, 1, -1, 1, 0, -2, -2, 2, 1, -1, 0, -1, -2, -1, 0, 2, 1, 1, -2, 0, 1, 0, -2, 1, -1, 1, 1, 1, 1, 0, 0, 1, -2, 0, 1, -1, 2, 1, 2, -1, 0, 2, -2, 2, -1, 2, 2, -1, -2, 1, -2, -1, -2, 0, -2, 1, 1, 1, -2, 1, 1, 0, 0, 2, 0, -2, 0, 2, 1, 0, -2, 1, 1, -1, -2, -1, 0, 1, 1, -2, 2, -1, -1, 1, -2, 1, -2, 1, -2, -1, 2, 2, 0, 1, 0, 1, -2, -2, -2, -2, 0, -2, 0, 1, 2, 2, 0, 2, -2, -2, 0, -1, -1, 2, -1, -1, -2, -2, 1, -2, 0, 0, -1, 0, 0, 2, -2, 0, 0, 1, -1, 1, -2, 1, 0, 2, 2, 1, 0, -1, 0, 0, 1, -1, -1, 2, 0, 2, -1, -1, 0, -2, -1, -1, 0, 0, 2, -1, 0, 2, -1, -1, 2, -1, 1, 2, 0, 1, 0, -1, -2, -2, 2, -1, 0, 0, 0, -2, 1, -2, 2, 0, -1, 2, 1, -2, 0, -1, 2, 0, -1, -2, -2, -1, 2, 1, -2, -2, -1, -2, 1, -2, 1, 1, 0, 1, 2, 1, -2, -1, -1, 1, 0, 1, 0, -1, -1, -2, -2, 1, -2, 0, 1, -2, -1, -2, 2, 0, 2, 2, 2, -1, -2, -1, 1, 0, -1, -1, -2, -1, 1, 2, -2, -1, 1, 2, -1, 1, -2, -2, 0, 0, 1, -2, -1, -2, -1, 1, 1, 1, 2, -2, -1, -2, -2, 0, 1, 1, 2, -2, -2, 1, -2, -2, 0, -2, 2, 1, 1, -2, 2, -2, 2, 2, 1, -2, -1, 1, -1, -2, -1, 2, -1, -1, 1, -2, -1, -1, -1, 2, -2, 2, 0, 0, -2, 0, 0, 2, -2, -1, 2, -2, 0, 2, 1, -2, -2, -1, -1, 2, -1, 1, -1, -1, 0, 2, -2, 1, -2, 1, 1, 1, 0, 2, 0, 0, -1, -1, 2, 2, -2, -2, 1, 2, 0, 0, -2, -2, 1, 0, 0, 1, 0, 1, -1, -1, -2, 1, 1, 1, -2, -1, -2, 1, 1, 0, 1, 1, -2, -1, -1, 0, 1, 2, 2, -2, -2, -1, 0, -2, 0, 1, -2, 2, -2, 1, 1, -1, 0, 0, -1, -1, 0, 1, 0, -2, -2, -2, 2, -2, -2, 0, -1, 0, 2, -2, -1, -1, -1, -1, 2, 2, 0, 2, 2, -1, 1, 0, -1] answered in 20.8101589679718  s\n",
            "Results: ['3225309.jpg', '2349671.jpg', '3203335.jpg', 'im22608.jpg', 'im16693.jpg', 'im23383.jpg', '2899260.jpg', 'im17515.jpg', '3414592.jpg', '1054252.jpg']\n",
            "Ricerca effettuata in: 20.812049388885498 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jar0skz-sPsx"
      },
      "source": [
        "## Index Fine Tuned"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAOZuyvBsSkj"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  vantage_point_tree = VP_Tree(\"index_fine_tuned\",height=10, disk_mode=True, leaves_path=INDEX_DIR)\n",
        "  vantage_point_tree.create_vptree(FINE_TUNED_ID, FINE_TUNED_FEATURES)\n",
        "\n",
        "  index_name = vantage_point_tree.index_name\n",
        "  dest_folder = os.path.join(INDEX_DIR, index_name)\n",
        "  print(\"Destination Folder: \", dest_folder)\n",
        "\n",
        "  VP_Tree.save_vptree(dest_folder,vantage_point_tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WuI5YBMsoXe",
        "outputId": "b71afe90-a5ca-46b1-d9b0-d19195997a92"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  dest_folder = os.path.join(INDEX_DIR, \"index_fine_tuned/index_fine_tuned.json\")\n",
        "  vantage_point_tree = VP_Tree.load_vptree(dest_folder)\n",
        "  query = [random.randint(-2,2) for _ in range(256)]\n",
        "  start = time.time()\n",
        "  nn, d_nn = vantage_point_tree.knn_search(k=10, query=query)\n",
        "  end = time.time()\n",
        "  print(\"Results:\", [element[0] for element in nn])\n",
        "  print(\"Ricerca effettuata in:\", end - start, \"s\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tree loaded correctly\n",
            "Query [0, -2, 1, 1, 2, 2, -1, -2, -1, 1, 1, 2, 2, -2, 2, 1, 0, 0, 0, 1, 1, 2, 2, 2, 0, 0, 1, 1, -1, 0, 0, 2, 1, -1, -1, 1, 1, 0, 2, -1, 1, -1, 1, -2, 1, -1, -1, -1, 1, -1, 0, -1, 0, -2, 0, 2, 1, 1, -1, -1, -2, -1, 1, 2, -1, 2, -2, -2, 0, -2, 1, 2, -2, -1, 2, 2, 0, -1, 0, 1, 1, -1, -1, 2, 2, -1, 0, -1, 0, 2, 1, 0, -2, 0, -2, -1, 1, -1, -1, 0, -2, 2, 1, -1, -1, 0, -2, 1, -2, -1, -2, 0, -1, 0, -2, -2, 2, 2, 1, -2, 2, 2, 2, -2, -1, 0, 1, 0, 0, -2, 2, -2, -1, 0, 1, 2, 1, -2, -2, 0, -1, 1, -1, 0, 1, 2, 1, -1, -1, -1, -2, 1, 1, -1, -1, 1, -1, -2, 0, 2, 1, 2, 1, -1, -2, -2, 2, 2, -1, 2, -2, 1, -1, -1, 1, 1, 1, 1, -2, -1, 2, -2, 1, 2, -1, 1, 1, 2, -1, 0, 1, 0, -2, -2, -1, 0, 2, -1, -2, -1, 1, 2, -2, -1, -1, 0, 2, 2, 0, -1, 0, 1, 0, -1, -2, 0, 0, -1, -1, -1, 0, -1, 1, 0, 1, -1, -1, -1, 2, 1, -2, -1, -1, -2, -2, 0, 1, 0, 0, -2, -1, -2, 0, 1, -1, 0, -2, 0, -1, -2, -2, 2, 0, 2, -1, -1] answered in 7.436039686203003  s\n",
            "Results: ['im6991.jpg', 'im13432.jpg', 'im13404.jpg', 'im14572.jpg', 'im2223.jpg', 'im16366.jpg', 'im7820.jpg', 'im13297.jpg', 'im12522.jpg', 'im23767.jpg']\n",
            "Ricerca effettuata in: 7.438694715499878 s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}